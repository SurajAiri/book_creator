{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               ID              SIZE      MODIFIED     \n",
      "llama3.2:latest    a80c4f17acd5    2.0 GB    2 weeks ago     \n",
      "phi3:latest        a2c89ceaed85    2.3 GB    5 months ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4z/8t5g8k3s159_f4j7xpxhn1t00000gn/T/ipykernel_1309/1558435396.py:5: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model='llama3.2',temperature=0.7)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import StringPromptTemplate, PromptTemplate\n",
    "\n",
    "# Initialize the LLM (GPT-3.5 or GPT-4)\n",
    "llm = Ollama(model='llama3.2',temperature=0.7)\n",
    "\n",
    "# Define a prompt template to generate the book structure in JSON\n",
    "structure_prompt_template = \"\"\"\n",
    "Book Context: {context}\n",
    "Book Genre: {genre}\n",
    "\n",
    "Based on the book context and above provided information, create a book structure in JSON format with the following details:\n",
    "1. Book title (at least 4 titles).\n",
    "2. Chapters, each with headings and subheadings.\n",
    "\n",
    "\n",
    "\n",
    "Return the structure in JSON format like this:\n",
    "{{\n",
    "  \"title\": [\"Book Title1\", \"Book Title2\", ...],\n",
    "  \"chapters\": [\n",
    "    {{\n",
    "      \"chapter_title\": \"Chapter 1\",\n",
    "      \"headings\": [\n",
    "        {{\n",
    "          \"heading\": \"Heading 1\",\n",
    "          \"subheadings\": [\"Subheading 1\", \"Subheading 2\"]\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "    \n",
    "  }},\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "\n",
    "don't return any other text except the JSON structure so that response can be parsed json.loads() function.\n",
    "\"\"\"\n",
    "\n",
    "structure_prompt_template = \"\"\"\n",
    "Book Context: {context}\n",
    "Book Genre: {genre}\n",
    "\n",
    "Using the provided book context and genre, create a complete book structure in JSON format with the following details:\n",
    "\n",
    "1. Generate at least 4 potential book titles.\n",
    "2. Organize the book into chapters, where each chapter includes:\n",
    "   - A chapter title\n",
    "   - Headings within the chapter\n",
    "   - Subheadings under each heading\n",
    "\n",
    "Return the output in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"title\": [\"Book Title1\", \"Book Title2\", \"Book Title3\", \"Book Title4\"],\n",
    "  \"chapters\": [\n",
    "    {{\n",
    "      \"chapter_title\": \"Chapter 1\",\n",
    "      \"headings\": [\n",
    "        {{\n",
    "          \"heading\": \"Heading 1\",\n",
    "          \"subheadings\": [\"Subheading 1\", \"Subheading 2\"]\n",
    "        }},\n",
    "        {{\n",
    "          \"heading\": \"Heading 2\",\n",
    "          \"subheadings\": [\"Subheading 1\", \"Subheading 2\"]\n",
    "        }}\n",
    "      ]\n",
    "    }},\n",
    "    {{\n",
    "      \"chapter_title\": \"Chapter 2\",\n",
    "      \"headings\": [\n",
    "        {{\n",
    "          \"heading\": \"Heading 1\",\n",
    "          \"subheadings\": [\"Subheading 1\", \"Subheading 2\"]\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Only return the JSON structure. No other text should be included so it can be easily parsed using the `json.loads()` function.\n",
    "\n",
    "\"\"\"\n",
    "# Function to generate book structure\n",
    "def generate_book_structure(context,genre):\n",
    "    prompt = PromptTemplate(input_variables=[\"context\",\"genre\"], template=structure_prompt_template).format(context=context, genre=genre)\n",
    "    structure_response = llm(prompt)\n",
    "    return structure_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4z/8t5g8k3s159_f4j7xpxhn1t00000gn/T/ipykernel_1309/1558435396.py:88: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  structure_response = llm(prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "{\n",
      "  \"title\": [\n",
      "    \"Understanding Natural Language Processing\",\n",
      "    \"Techniques and Applications of NLP\",\n",
      "    \"Advanced Methods in NLP\",\n",
      "    \"Real-world Implementations of NLP\"\n",
      "  ],\n",
      "  \"chapters\": [\n",
      "    {\n",
      "      \"chapter_title\": \"Introduction to NLP\",\n",
      "      \"headings\": [\n",
      "        {\n",
      "          \"heading\": \"What is NLP?\",\n",
      "          \"subheadings\": [\"Definition\", \"Purpose\"]\n",
      "        },\n",
      "        {\n",
      "          \"heading\": \"History of NLP\",\n",
      "          \"subheadings\": [\"Early Developments\", \"Current Trends\"]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"chapter_title\": \"Text Preprocessing\",\n",
      "      \"headings\": [\n",
      "        {\n",
      "          \"heading\": \"Tokenization\",\n",
      "          \"subheadings\": [\"Types of Tokenization\", \"Common Challenges\"]\n",
      "        },\n",
      "        {\n",
      "          \"heading\": \"Stopword Removal\",\n",
      "          \"subheadings\": [\"Why Remove Stopwords?\", \"Methods and Tools\"]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"chapter_title\": \"Sentiment Analysis\",\n",
      "      \"headings\": [\n",
      "        {\n",
      "          \"heading\": \"Basic Sentiment Analysis Techniques\",\n",
      "          \"subheadings\": [\"Rule-based Methods\", \"Machine Learning Approaches\"]\n",
      "        },\n",
      "        {\n",
      "          \"heading\": \"Advanced Sentiment Analysis Models\",\n",
      "          \"subheadings\": [\"Deep Learning Architectures\", \"Ensemble Methods\"]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"chapter_title\": \"Named Entity Recognition\",\n",
      "      \"headings\": [\n",
      "        {\n",
      "          \"heading\": \"Basic NER Techniques\",\n",
      "          \"subheadings\": [\"Rule-based Methods\", \"Machine Learning Approaches\"]\n",
      "        },\n",
      "        {\n",
      "          \"heading\": \"Advanced NER Models\",\n",
      "          \"subheadings\": [\"Deep Learning Architectures\", \"Ensemble Methods\"]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prompt = PromptTemplate(input_variables=[\"context\"], template=structure_prompt_template)\n",
    "# prompt.invoke({\"context\":\"The book is about a detective who solves crime in sifi world.\"})\n",
    "BOOK_CONTEXT = \"Techniques used in NLP\"\n",
    "GENRE = \"Artificial Intelligence\"\n",
    "\n",
    "p = generate_book_structure(context=BOOK_CONTEXT, genre=GENRE)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text to json\n",
    "# import json\n",
    "# data = json.loads(p)\n",
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "# data = json.loads(p)\n",
    "\n",
    "# def extract_and_parse_json(llm_output):\n",
    "#     try:\n",
    "#         # Use regex to find the first occurrence of a JSON object\n",
    "#         json_match = re.search(r'\\{.*?\\}', llm_output, re.DOTALL)\n",
    "        \n",
    "#         if json_match:\n",
    "#             # Extract the JSON string\n",
    "#             json_str = json_match.group(0)\n",
    "            \n",
    "#             # Parse the JSON string into a Python dictionary\n",
    "#             parsed_json = json.loads(json_str)\n",
    "#             return parsed_json\n",
    "#         else:\n",
    "#             print(\"No valid JSON found in the LLM output.\")\n",
    "#             return None\n",
    "#     except json.JSONDecodeError as e:\n",
    "#         print(f\"Error parsing JSON: {e}\")\n",
    "#         return None\n",
    "\n",
    "\n",
    "# def extract_and_parse_json(llm_output):\n",
    "#     try:\n",
    "#         # Use regex to find JSON content between triple backticks and curly braces\n",
    "#         json_match = re.search(r'```.*?(\\{.*?\\})```', llm_output, re.DOTALL)\n",
    "        \n",
    "#         if json_match:\n",
    "#             # Extract the JSON string\n",
    "#             json_str = json_match.group(1)  # Group 1 contains the actual JSON\n",
    "            \n",
    "#             # Parse the JSON string into a Python dictionary\n",
    "#             parsed_json = json.loads(json_str)\n",
    "#             return parsed_json\n",
    "#         else:\n",
    "#             print(\"No valid JSON found in the LLM output.\")\n",
    "#             return None\n",
    "#     except json.JSONDecodeError as e:\n",
    "#         print(f\"Error parsing JSON: {e}\")\n",
    "#         return None\n",
    "\n",
    "def extract_and_parse_json(llm_output):\n",
    "    try:\n",
    "        # Use regex to find JSON content between triple backticks and curly braces\n",
    "        json_match = re.search(r'```.*?(\\{.*?\\})```', llm_output, re.DOTALL)\n",
    "        \n",
    "        if json_match:\n",
    "            # Extract the JSON string\n",
    "            json_str = json_match.group(1)  # Group 1 contains the actual JSON\n",
    "            \n",
    "            # Clean up the JSON string by removing newlines and extra spaces\n",
    "            json_str = re.sub(r'\\s+', ' ', json_str)  # Replace multiple spaces/newlines with a single space\n",
    "            json_str = json_str.strip()  # Remove leading/trailing whitespace\n",
    "            \n",
    "            # Parse the cleaned JSON string into a Python dictionary\n",
    "            parsed_json = json.loads(json_str)\n",
    "            return parsed_json\n",
    "        else:\n",
    "            print(\"No valid JSON found in the LLM output.\")\n",
    "            return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(input_string):\n",
    "    # Remove leading and trailing whitespace\n",
    "    input_string = input_string.strip()\n",
    "\n",
    "    # Check if the input is in the 'json' block format\n",
    "    if input_string.startswith('```json'):\n",
    "        # Extract the JSON content between the backticks\n",
    "        json_content = re.search(r'```json\\s*(.*?)\\s*```', input_string, re.DOTALL)\n",
    "        if json_content:\n",
    "            json_string = json_content.group(1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid JSON format\")\n",
    "    elif input_string.startswith('```'):\n",
    "        # Extract the JSON content between the backticks\n",
    "        json_content = re.search(r'```\\s*(.*?)\\s*```', input_string, re.DOTALL)\n",
    "        if json_content:\n",
    "            json_string = json_content.group(1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid JSON format\")\n",
    "    else:\n",
    "        # Treat the input as normal JSON\n",
    "        json_string = input_string\n",
    "\n",
    "    # Attempt to parse the JSON\n",
    "    try:\n",
    "        return json.loads(json_string)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Failed to decode JSON: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': ['Understanding Natural Language Processing', 'Techniques and Applications of NLP', 'Advanced Methods in NLP', 'Real-world Implementations of NLP'], 'chapters': [{'chapter_title': 'Introduction to NLP', 'headings': [{'heading': 'What is NLP?', 'subheadings': ['Definition', 'Purpose']}, {'heading': 'History of NLP', 'subheadings': ['Early Developments', 'Current Trends']}]}, {'chapter_title': 'Text Preprocessing', 'headings': [{'heading': 'Tokenization', 'subheadings': ['Types of Tokenization', 'Common Challenges']}, {'heading': 'Stopword Removal', 'subheadings': ['Why Remove Stopwords?', 'Methods and Tools']}]}, {'chapter_title': 'Sentiment Analysis', 'headings': [{'heading': 'Basic Sentiment Analysis Techniques', 'subheadings': ['Rule-based Methods', 'Machine Learning Approaches']}, {'heading': 'Advanced Sentiment Analysis Models', 'subheadings': ['Deep Learning Architectures', 'Ensemble Methods']}]}, {'chapter_title': 'Named Entity Recognition', 'headings': [{'heading': 'Basic NER Techniques', 'subheadings': ['Rule-based Methods', 'Machine Learning Approaches']}, {'heading': 'Advanced NER Models', 'subheadings': ['Deep Learning Architectures', 'Ensemble Methods']}]}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = parse_json(p)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction to NLP\n",
      "Text Preprocessing\n",
      "Sentiment Analysis\n",
      "Named Entity Recognition\n"
     ]
    }
   ],
   "source": [
    "for chapter in data['chapters']:\n",
    "    print(chapter['chapter_title'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a prompt template to generate chapter content in markdown\n",
    "# chapter_content_prompt_template = \"\"\"\n",
    "# Based on the following chapter structure, generate a detailed content in markdown format.\n",
    "\n",
    "# Chapter Title: {chapter_title}\n",
    "# Agenda: A brief description of the agenda for this chapter.\n",
    "\n",
    "# Headings and subheadings:\n",
    "# {headings}\n",
    "\n",
    "# Return the content in markdown format, structured by headings and subheadings.\n",
    "# \"\"\"\n",
    "\n",
    "# # Function to generate chapter content\n",
    "# def generate_chapter_content(chapter_title, headings):\n",
    "#     prompt = PromptTemplate(input_variables=[\"chapter_title\", \"headings\"], template=chapter_content_prompt_template).format(\n",
    "#         chapter_title=chapter_title, headings=headings)\n",
    "#     chapter_content = llm(prompt)\n",
    "#     return chapter_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import docx\n",
    "\n",
    "# # Function to save book content to Word\n",
    "# def save_to_word(book_title, chapters):\n",
    "#     doc = docx.Document()\n",
    "    \n",
    "#     # Set the title of the book\n",
    "#     doc.add_heading(book_title, 0)\n",
    "    \n",
    "#     for chapter in chapters:\n",
    "#         doc.add_heading(chapter['chapter_title'], level=1)\n",
    "        \n",
    "#         for heading in chapter['headings']:\n",
    "#             doc.add_heading(heading['heading'], level=2)\n",
    "            \n",
    "#             if 'subheadings' in heading:\n",
    "#                 for subheading in heading['subheadings']:\n",
    "#                     doc.add_heading(subheading, level=3)\n",
    "#                     # Insert content (in real use case, this would be the generated content)\n",
    "#                     doc.add_paragraph(\"This is content for subheading: \" + subheading)\n",
    "    \n",
    "#     # Save the document\n",
    "#     doc.save(\"generated_book.docx\")\n",
    "\n",
    "# # Example usage with a JSON structure (replace with actual structure)\n",
    "# save_to_word(book_structure['title'], book_structure['chapters'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chapter in data['chapters']:\n",
    "#     print(chapter['chapter_title'])\n",
    "#     chapter_data = generate_chapter_content(chapter['chapter_title'], chapter['headings'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypandoc\n",
    "\n",
    "# Function to convert markdown to a .docx file\n",
    "def markdown_to_docx(markdown_content, output_file):\n",
    "    output = pypandoc.convert_text(markdown_content, 'docx', format='md', outputfile=output_file)\n",
    "    if output == 0:\n",
    "        print(f\"File '{output_file}' created successfully!\")\n",
    "    else:\n",
    "        print(f\"Failed to create file {output} '{output_file}'.\")\n",
    "\n",
    "# # Example usage\n",
    "# chapter_content = \"\"\"\n",
    "# # Chapter 1: Introduction\n",
    "\n",
    "# ## What is AI?\n",
    "\n",
    "# Artificial Intelligence (AI) is the simulation of human intelligence in machines.\n",
    "\n",
    "# ## History of AI\n",
    "\n",
    "# AI has been around since the mid-20th century, with the development of early neural networks and expert systems.\n",
    "# <div style=\"page-break-before:always\">&nbsp;</div>\n",
    "# <p></p>\n",
    "# ### Types of AI\n",
    "\n",
    "# - Narrow AI\n",
    "# - General AI\n",
    "# - Superintelligence\n",
    "# \"\"\"\n",
    "\n",
    "# # Save the markdown content as a .docx file\n",
    "# markdown_to_docx(chapter_content, \"Chapter_1_Introduction.docx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def append_markdown_to_docx(large_docx_path, markdown_path, output_path):\n",
    "    # Step 1: Convert markdown to docx using Pandoc\n",
    "    temp_docx = \"temp_small_file.docx\"\n",
    "    subprocess.run(['pandoc', markdown_path, '-o', temp_docx])\n",
    "    \n",
    "    # Step 2: Append the converted docx to the large docx\n",
    "    subprocess.run(['pandoc', large_docx_path, temp_docx, '-o', output_path])\n",
    "\n",
    "# Example usage\n",
    "# append_markdown_to_docx('large_file.docx', 'small_file.md', 'merged_output.docx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "def append_markdown_to_docx(large_docx_path, markdown_content, output_docx_path):\n",
    "    # Step 1: Create a temporary markdown file from in-memory content\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".md\") as temp_md_file:\n",
    "        temp_md_file.write(markdown_content.encode('utf-8'))\n",
    "        temp_md_file.flush()  # Make sure the content is written to disk\n",
    "        temp_md_file_path = temp_md_file.name\n",
    "    \n",
    "    # Step 2: Convert the temporary markdown file to a temporary docx file using Pandoc\n",
    "    temp_docx_file_path = tempfile.mktemp(suffix=\".docx\")\n",
    "    subprocess.run(['pandoc', temp_md_file_path, '-o', temp_docx_file_path])\n",
    "    \n",
    "    # Step 3: Append the converted docx to the large docx file\n",
    "    subprocess.run(['pandoc', large_docx_path, temp_docx_file_path, '-o', output_docx_path])\n",
    "\n",
    "    # Step 4: Clean up the temporary files\n",
    "    os.remove(temp_md_file_path)\n",
    "    os.remove(temp_docx_file_path)\n",
    "\n",
    "# Example usage\n",
    "large_docx_path = 'Chapter_1_Introduction.docx'  # Path to the large docx file\n",
    "markdown_content = \"# Chapter 2\\nThis is the content of chapter 2 in markdown format.\"  # Your in-memory markdown\n",
    "output_docx_path = 'merged_output.docx'  # Output docx file after merging\n",
    "\n",
    "append_markdown_to_docx(large_docx_path, markdown_content, output_docx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_doc_file(file_path,content):\n",
    "    if os.path.exists(file_path):\n",
    "        append_markdown_to_docx(file_path, content, file_path)\n",
    "    else:\n",
    "        markdown_to_docx(content, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_doc_file(\"1.docx\",markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': ['Understanding Natural Language Processing',\n",
       "  'Techniques and Applications of NLP',\n",
       "  'Advanced Methods in NLP',\n",
       "  'Real-world Implementations of NLP'],\n",
       " 'chapters': [{'chapter_title': 'Introduction to NLP',\n",
       "   'headings': [{'heading': 'What is NLP?',\n",
       "     'subheadings': ['Definition', 'Purpose']},\n",
       "    {'heading': 'History of NLP',\n",
       "     'subheadings': ['Early Developments', 'Current Trends']}]},\n",
       "  {'chapter_title': 'Text Preprocessing',\n",
       "   'headings': [{'heading': 'Tokenization',\n",
       "     'subheadings': ['Types of Tokenization', 'Common Challenges']},\n",
       "    {'heading': 'Stopword Removal',\n",
       "     'subheadings': ['Why Remove Stopwords?', 'Methods and Tools']}]},\n",
       "  {'chapter_title': 'Sentiment Analysis',\n",
       "   'headings': [{'heading': 'Basic Sentiment Analysis Techniques',\n",
       "     'subheadings': ['Rule-based Methods', 'Machine Learning Approaches']},\n",
       "    {'heading': 'Advanced Sentiment Analysis Models',\n",
       "     'subheadings': ['Deep Learning Architectures', 'Ensemble Methods']}]},\n",
       "  {'chapter_title': 'Named Entity Recognition',\n",
       "   'headings': [{'heading': 'Basic NER Techniques',\n",
       "     'subheadings': ['Rule-based Methods', 'Machine Learning Approaches']},\n",
       "    {'heading': 'Advanced NER Models',\n",
       "     'subheadings': ['Deep Learning Architectures', 'Ensemble Methods']}]}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imagine you are an author crafting a book. You need to write a compelling introduction for a specific chapter, emphasizing its overall theme and significance. You have the following details:\n",
      "\n",
      "Book Context: Techniques used in NLP\n",
      "Book Genre: Artificial Intelligence\n",
      "\n",
      "Chapter Title: Introduction to NLP\n",
      "Headings to be Covered: [{'heading': 'What is NLP?', 'subheadings': ['Definition', 'Purpose']}, {'heading': 'History of NLP', 'subheadings': ['Early Developments', 'Current Trends']}]\n",
      "\n",
      "Please provide a markdown-formatted introduction that outlines the main ideas and themes of the chapter. The introduction should capture the essence of what will be discussed, including relevant examples or a narrative, while avoiding any specific mention of the headings or subheadings. Focus on setting the stage for the reader, highlighting the chapter's importance and intriguing aspects without breaking it down into bullet points, as those will be addressed later in detail.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# chapter_brief_template = \"\"\"\n",
    "# Suppose you are a book author and you are writing a book. You have a chapter in your book that you want to write a brief about. You have the following information:\n",
    "# Book context: {context}\n",
    "# Book genre: {genre}\n",
    "\n",
    "# Chapter: {chapter}\n",
    "# with these headings: {headings}\n",
    "\n",
    "# return the content in markdown format for the chapter chapter introduction and basic agenda about what is going to be covered in the chapter. Keep it in mind that headings and sub headings will be covered in the next steps.\n",
    "# \"\"\"\n",
    "\n",
    "chapter_brief_template = \"\"\"\n",
    "Imagine you are an author crafting a book. You need to write a compelling introduction for a specific chapter, emphasizing its overall theme and significance. You have the following details:\n",
    "\n",
    "Book Context: {context}\n",
    "Book Genre: {genre}\n",
    "\n",
    "Chapter Title: {chapter}\n",
    "Headings to be Covered: {headings}\n",
    "\n",
    "Please provide a markdown-formatted introduction that outlines the main ideas and themes of the chapter. The introduction should capture the essence of what will be discussed, including relevant examples or a narrative, while avoiding any specific mention of the headings or subheadings. Focus on setting the stage for the reader, highlighting the chapter's importance and intriguing aspects without breaking it down into bullet points, as those will be addressed later in detail.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "chapter_prompt = PromptTemplate(input_variables=[\"context\",\"genre\",\"chapter\",\"headings\"], template=chapter_brief_template)\n",
    "\n",
    "t = chapter_prompt.format(context=BOOK_CONTEXT, genre=GENRE, chapter=data['chapters'][0]['chapter_title'], headings=data['chapters'][0]['headings'],)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Unlocking the Power of Human Language: The Foundations of NLP**\n",
      "\n",
      "As artificial intelligence continues to revolutionize industries and transform the way we interact with technology, one crucial aspect has emerged as a linchpin in the development of intelligent machines: Natural Language Processing (NLP). The ability to understand, interpret, and generate human language is no longer a nicety, but a necessity for creating truly conversational AI systems. In this chapter, we will delve into the heart of NLP, exploring its definition, purpose, and evolution.\n",
      "\n",
      "Imagine a world where machines can not only process vast amounts of data but also comprehend the nuances of human communication. A world where language barriers are bridged, and machines can converse with humans in their own language. This is the promise of NLP, and it's an area that has gained significant traction in recent years, driven by advancements in machine learning, deep learning, and cognitive computing.\n",
      "\n",
      "From its humble beginnings as a research field to its current applications in virtual assistants, sentiment analysis, and chatbots, NLP has come a long way. But what makes NLP so essential for AI development? How does it enable machines to understand human language, and what are the implications of this technology on our society?\n",
      "\n",
      "In the following pages, we will embark on a journey to uncover the fundamentals of NLP, exploring its history, key concepts, and applications. We'll examine how NLP is being used today to improve language understanding, generate human-like text, and even create more empathetic chatbots. By the end of this chapter, you'll gain a deeper understanding of the power and potential of NLP, and why it's an area that will continue to shape the future of artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are author crafting book. You have done chapter introduction and going to write about heading. You have following information:\n",
      "\n",
      "Book Context: Techniques used in NLP\n",
      "Book Genre: Artificial Intelligence\n",
      "Chapter Title: Introduction to NLP\n",
      "Heading: What is NLP?\n",
      "Heading Index: 1\n",
      "Sub-Headings: ['Definition', 'Purpose']\n",
      "\n",
      "Return the content in markdown format for the heading What is NLP? in the chapter Introduction to NLP. The content should provide a detailed overview of the heading, including key points, examples, and any relevant information that will help readers understand the topic. Avoid going into subheadings at this stage and focus on creating a comprehensive narrative for the heading.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heading_brief_template = \"\"\"\n",
    "You are author crafting book. You have done chapter introduction and going to write about heading. You have following information:\n",
    "\n",
    "Book Context: {context}\n",
    "Book Genre: {genre}\n",
    "Chapter Title: {chapter}\n",
    "Heading: {heading}\n",
    "Heading Index: {index}\n",
    "Sub-Headings: {sub_headings}\n",
    "\n",
    "Return the content in markdown format for the heading {heading} in the chapter {chapter}. The content should provide a detailed overview of the heading, including key points, examples, and any relevant information that will help readers understand the topic. Avoid going into subheadings at this stage and focus on creating a comprehensive narrative for the heading.\n",
    "\"\"\"\n",
    "\n",
    "heading_prompt = PromptTemplate(input_variables=[\"context\",\"genre\",\"chapter\",\"heading\",\"index\",\"sub_headings\"], template=heading_brief_template)\n",
    "p = heading_prompt.format(context=BOOK_CONTEXT, genre=GENRE, chapter=data['chapters'][0]['chapter_title'], heading=data['chapters'][0]['headings'][0]['heading'], index=1, sub_headings=data['chapters'][0]['headings'][0]['subheadings'])\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# What is NLP?\n",
      "\n",
      "NLP stands for Natural Language Processing, a subfield of artificial intelligence (AI) that deals with the interaction between computers and humans in natural language. At its core, NLP aims to enable machines to understand, interpret, and generate human language.\n",
      "\n",
      "In essence, NLP is about developing algorithms and statistical models that can process and make sense of human language, allowing computers to analyze, classify, categorize, and extract insights from vast amounts of text data. This enables machines to perform tasks such as speech recognition, sentiment analysis, machine translation, text summarization, and more.\n",
      "\n",
      "NLP has numerous applications across various industries, including but not limited to:\n",
      "\n",
      "* Sentiment analysis in customer service\n",
      "* Speech recognition in voice assistants\n",
      "* Machine translation in international business\n",
      "* Text classification in spam detection\n",
      "\n",
      "The field of NLP is rapidly evolving, with advancements in deep learning techniques, neural networks, and big data analytics. As a result, NLP has become an essential component of AI systems, enabling them to better understand human language and interact with humans more effectively.\n",
      "\n",
      "In the following sections, we will delve deeper into the world of NLP, exploring its definition, purpose, and applications in detail.\n"
     ]
    }
   ],
   "source": [
    "res = llm(p)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "you are author crafting book. You have done chapter introduction and heading. Now you are going to write about sub-heading. You have following information:\n",
      "\n",
      "Book Context: Techniques used in NLP\n",
      "Book Genre: Artificial Intelligence\n",
      "Chapter Title: Introduction to NLP\n",
      "Heading: What is NLP?\n",
      "Sub-Heading Index: 1\n",
      "\n",
      "Return the content in markdown format for the sub-heading Definition under the heading What is NLP? in the chapter Introduction to NLP. The content should provide a detailed overview of the sub-heading, including key points, examples, and any relevant information that will help readers understand the topic. Focus on creating a narrative that complements the heading and adds depth to the chapter's structure.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sub_heading_brief_template = \"\"\"\n",
    "you are author crafting book. You have done chapter introduction and heading. Now you are going to write about sub-heading. You have following information:\n",
    "\n",
    "Book Context: {context}\n",
    "Book Genre: {genre}\n",
    "Chapter Title: {chapter}\n",
    "Heading: {heading}\n",
    "Sub-Heading Index: {index}\n",
    "\n",
    "Return the content in markdown format for the sub-heading {sub_heading} under the heading {heading} in the chapter {chapter}. The content should provide a detailed overview of the sub-heading, including key points, examples, and any relevant information that will help readers understand the topic. Focus on creating a narrative that complements the heading and adds depth to the chapter's structure.\n",
    "\"\"\"\n",
    "\n",
    "sub_heading_prompt = PromptTemplate(input_variables=[\"context\",\"genre\",\"chapter\",\"heading\",\"sub_heading\",\"index\"], template=sub_heading_brief_template)\n",
    "p = sub_heading_prompt.format(context=BOOK_CONTEXT, genre=GENRE, chapter=data['chapters'][0]['chapter_title'], heading=data['chapters'][0]['headings'][0]['heading'], sub_heading=data['chapters'][0]['headings'][0]['subheadings'][0], index=1)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**What is NLP?**\n",
      "\n",
      "### Definition\n",
      "#### **1. Understanding the Foundations of NLP**\n",
      "\n",
      "NLP (Natural Language Processing) is a subfield of artificial intelligence (AI) that deals with the interaction between computers and humans in natural language. It encompasses a range of techniques and methods used to enable computers to understand, interpret, and generate human language.\n",
      "\n",
      "At its core, NLP aims to bridge the gap between human communication and machine processing, allowing computers to comprehend and respond to human input in a more effective and intuitive manner. This is achieved through a combination of natural language understanding (NLU), speech recognition, text analysis, and machine learning algorithms.\n",
      "\n",
      "To illustrate this concept, consider a simple example: imagine a virtual assistant like Siri or Alexa. When you ask Siri a question or provide feedback, it uses NLP to understand your voice, intent, and context, allowing it to respond accordingly. This process involves multiple stages of processing, including speech recognition, natural language understanding, and machine learning-driven response generation.\n",
      "\n",
      "In the context of artificial intelligence, NLP plays a crucial role in enabling machines to learn from human language data, extract insights, and make predictions based on patterns and relationships within that data. By developing more sophisticated NLP systems, researchers and developers can create intelligent machines that are capable of understanding and responding to human communication in a more natural and effective way.\n",
      "\n",
      "In the following sections, we will delve deeper into the world of NLP, exploring its history, key concepts, techniques, and applications in detail.\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bookEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
