{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOK_CONTEXT = \"Techniques used in NLP\"\n",
    "GENRE = \"Artificial Intelligence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import  PromptTemplate\n",
    "\n",
    "# Initialize the LLM (GPT-3.5 or GPT-4)\n",
    "llm = Ollama(model='llama3.2',temperature=0.7)\n",
    "\n",
    "# Define a prompt template to generate the book structure in JSON\n",
    "structure_prompt_template = \"\"\"\n",
    "Book Context: {context}\n",
    "Book Genre: {genre}\n",
    "\n",
    "Based on the book context and above provided information, create a book structure in JSON format with the following details:\n",
    "1. Book title (at least 4 titles).\n",
    "2. Chapters, each with headings and subheadings.\n",
    "\n",
    "\n",
    "\n",
    "Return the structure in JSON format like this:\n",
    "{{\n",
    "  \"title\": [\"Book Title1\", \"Book Title2\", ...],\n",
    "  \"chapters\": [\n",
    "    {{\n",
    "      \"chapter_title\": \"Chapter 1\",\n",
    "      \"headings\": [\n",
    "        {{\n",
    "          \"heading\": \"Heading 1\",\n",
    "          \"subheadings\": [\"Subheading 1\", \"Subheading 2\"]\n",
    "        }}\n",
    "      ]\n",
    "    }},\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "\n",
    "don't return anything except the JSON structure.\n",
    "\"\"\"\n",
    "\n",
    "# Function to generate book structure\n",
    "def generate_book_structure(context,genre):\n",
    "    prompt = PromptTemplate(input_variables=[\"context\",\"genre\"], template=structure_prompt_template).format(context=context, genre=genre)\n",
    "    structure_response = llm(prompt)\n",
    "    return structure_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": [\n",
      "    \"Introduction to NLP with AI\",\n",
      "    \"Text Preprocessing and Tokenization Techniques\",\n",
      "    \"Machine Learning for NLP Applications\",\n",
      "    \"Deep Learning Models in Natural Language Processing\"\n",
      "  ],\n",
      "  \"chapters\": [\n",
      "    {\n",
      "      \"chapter_title\": \"Chapter 1: Introduction to NLP\",\n",
      "      \"headings\": [\n",
      "        {\n",
      "          \"heading\": \"1.1 Overview of NLP\",\n",
      "          \"subheadings\": [\"Subheading 1.1\", \"Subheading 1.2\"]\n",
      "        },\n",
      "        {\n",
      "          \"heading\": \"1.2 Types of NLP\",\n",
      "          \"subheadings\": [\"Subheading 1.3\", \"Subheading 1.4\"]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"chapter_title\": \"Chapter 2: Text Preprocessing and Tokenization\",\n",
      "      \"headings\": [\n",
      "        {\n",
      "          \"heading\": \"2.1 Text Cleaning Techniques\",\n",
      "          \"subheadings\": [\"Subheading 2.1\", \"Subheading 2.2\"]\n",
      "        },\n",
      "        {\n",
      "          \"heading\": \"2.2 Tokenization Methods\",\n",
      "          \"subheadings\": [\"Subheading 2.3\", \"Subheading 2.4\"]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"chapter_title\": \"Chapter 3: Machine Learning for NLP Applications\",\n",
      "      \"headings\": [\n",
      "        {\n",
      "          \"heading\": \"3.1 Supervised Learning Algorithms\",\n",
      "          \"subheadings\": [\"Subheading 3.1\", \"Subheading 3.2\"]\n",
      "        },\n",
      "        {\n",
      "          \"heading\": \"3.2 Unsupervised Learning Techniques\",\n",
      "          \"subheadings\": [\"Subheading 3.3\", \"Subheading 3.4\"]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"chapter_title\": \"Chapter 4: Deep Learning Models in Natural Language Processing\",\n",
      "      \"headings\": [\n",
      "        {\n",
      "          \"heading\": \"4.1 Word Embeddings and Neural Networks\",\n",
      "          \"subheadings\": [\"Subheading 4.1\", \"Subheading 4.2\"]\n",
      "        },\n",
      "        {\n",
      "          \"heading\": \"4.2 Recurrent Neural Networks for NLP\",\n",
      "          \"subheadings\": [\"Subheading 4.3\", \"Subheading 4.4\"]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "p = generate_book_structure(context=BOOK_CONTEXT, genre=GENRE)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text to json\n",
    "import json\n",
    "import re\n",
    "# data = json.loads(p)\n",
    "def parse_json(input_string):\n",
    "    # Remove leading and trailing whitespace\n",
    "    input_string = input_string.strip()\n",
    "\n",
    "    # Check if the input is in the 'json' block format\n",
    "    if input_string.startswith('```json'):\n",
    "        # Extract the JSON content between the backticks\n",
    "        json_content = re.search(r'```json\\s*(.*?)\\s*```', input_string, re.DOTALL)\n",
    "        if json_content:\n",
    "            json_string = json_content.group(1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid JSON format\")\n",
    "    elif input_string.startswith('```'):\n",
    "        # Extract the JSON content between the backticks\n",
    "        json_content = re.search(r'```\\s*(.*?)\\s*```', input_string, re.DOTALL)\n",
    "        if json_content:\n",
    "            json_string = json_content.group(1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid JSON format\")\n",
    "    else:\n",
    "        # Treat the input as normal JSON\n",
    "        json_string = input_string\n",
    "\n",
    "    # Attempt to parse the JSON\n",
    "    try:\n",
    "        return json.loads(json_string)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Failed to decode JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypandoc\n",
    "\n",
    "# Function to convert markdown to a .docx file\n",
    "def markdown_to_docx(markdown_content, output_file):\n",
    "    try:\n",
    "        # Attempt to convert the markdown content to docx and save it\n",
    "        output = pypandoc.convert_text(markdown_content, 'docx', format='md', outputfile=output_file)\n",
    "        \n",
    "        # The output is 0 if successful\n",
    "        if output == 0 or output == \"\":\n",
    "            print(f\"File '{output_file}' created successfully!\")\n",
    "        else:\n",
    "            print(f\"Failed to create file '{output_file}'. Output: {output}\")\n",
    "    except OSError as e:\n",
    "        # Print the error if pandoc isn't found or the conversion fails\n",
    "        print(f\"Conversion failed. Error: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "def append_markdown_to_docx(large_docx_path, markdown_content, output_docx_path):\n",
    "    # Step 1: Create a temporary markdown file from in-memory content\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".md\") as temp_md_file:\n",
    "        temp_md_file.write(markdown_content.encode('utf-8'))\n",
    "        temp_md_file.flush()  # Make sure the content is written to disk\n",
    "        temp_md_file_path = temp_md_file.name\n",
    "    \n",
    "    # Step 2: Convert the temporary markdown file to a temporary docx file using Pandoc\n",
    "    temp_docx_file_path = tempfile.mktemp(suffix=\".docx\")\n",
    "    subprocess.run(['pandoc', temp_md_file_path, '-o', temp_docx_file_path])\n",
    "    \n",
    "    # Step 3: Append the converted docx to the large docx file\n",
    "    subprocess.run(['pandoc', large_docx_path, temp_docx_file_path, '-o', output_docx_path])\n",
    "\n",
    "    # Step 4: Clean up the temporary files\n",
    "    os.remove(temp_md_file_path)\n",
    "    os.remove(temp_docx_file_path)\n",
    "\n",
    "# # Example usage\n",
    "# large_docx_path = 'Chapter_1_Introduction.docx'  # Path to the large docx file\n",
    "# markdown_content = \"# Chapter 2\\nThis is the content of chapter 2 in markdown format.\"  # Your in-memory markdown\n",
    "# output_docx_path = 'merged_output.docx'  # Output docx file after merging\n",
    "\n",
    "# append_markdown_to_docx(large_docx_path, markdown_content, output_docx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_doc_file(file_path,content):\n",
    "    if os.path.exists(file_path):\n",
    "        append_markdown_to_docx(file_path, content, file_path)\n",
    "    else:\n",
    "        markdown_to_docx(content, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_brief_template = \"\"\"\n",
    "Imagine you are an author crafting a book. You need to write a compelling introduction for a specific chapter, emphasizing its overall theme and significance. You have the following details:\n",
    "\n",
    "Book Context: {context}\n",
    "Book Genre: {genre}\n",
    "\n",
    "Chapter Title: {chapter}\n",
    "Headings to be Covered: {headings}\n",
    "\n",
    "Please provide a markdown-formatted introduction that outlines the main ideas and themes of the chapter. The introduction should capture the essence of what will be discussed, including relevant examples or a narrative, while avoiding any specific mention of the headings or subheadings. Focus on setting the stage for the reader, highlighting the chapter's importance and intriguing aspects without breaking it down into bullet points, as those will be addressed later in detail.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "chapter_prompt = PromptTemplate(input_variables=[\"context\",\"genre\",\"chapter\",\"headings\"], template=chapter_brief_template)\n",
    "\n",
    "t = chapter_prompt.format(context=BOOK_CONTEXT, genre=GENRE, chapter=data['chapters'][0]['chapter_title'], headings=data['chapters'][0]['headings'],)\n",
    "print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bookEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
